{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_between(s, start, end):\n",
    "    return (s.split(start))[1].split(end)[0]\n",
    "\n",
    "def normalize_json(data: dict) -> dict:\n",
    "  \n",
    "    new_data = dict()\n",
    "    for key, value in data.items():\n",
    "        if not isinstance(value, dict):\n",
    "            new_data[key] = value\n",
    "        else:\n",
    "            for k, v in value.items():\n",
    "                new_data[key + \"_\" + k] = v\n",
    "  \n",
    "    return new_data\n",
    "    \n",
    "def read_files(filepath):\n",
    "    \"\"\"Reads file into csv\n",
    "\n",
    "    Args:\n",
    "        filepath (str): location of the file to read to csv\n",
    "    \"\"\"\n",
    "    df = []\n",
    "    ignore_file = '__MACOSX'\n",
    "    with ZipFile(filepath, \"r\") as z:\n",
    "        for filename in z.namelist()[1:]: #Skip root folder folder/\n",
    "            if ignore_file not in filename:\n",
    "                    # print(filename)  \n",
    "                    with z.open(filename, 'r') as f:  \n",
    "                        data = f.read()  \n",
    "                        df.append(pd.json_normalize(json.loads(data))) \n",
    "                        \n",
    "    df = pd.concat(df)\n",
    "    df = df.set_index(df.columns[0]) # Set first column as index\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_news_files(filepath, is_fake_news, type_of_file):\n",
    "    \"\"\"Extracts data from politifact_fake and politifact_real and converts to dataframe\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Zip filepath\n",
    "        is_fake_news (bool): Zip file classification\n",
    "        type_of_file (str): subfolder name for the news article for users that have: retweet, likes, tweet, reply\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: dataframe\n",
    "    \"\"\"\n",
    "    df = []\n",
    "    ignore_file = '__MACOSX'\n",
    "    with ZipFile(filepath, \"r\") as zip:\n",
    "        for zipname in tqdm(zip.namelist()[1:]):\n",
    "            zfiledata = BytesIO(zip.read(zipname))\n",
    "\n",
    "            with ZipFile(zfiledata, \"r\") as z:\n",
    "                for filename in z.namelist(): #Skip root folder folder/\n",
    "                    if re.search('^'+type_of_file+'/[a-zA-Z0-9].', filename):\n",
    "                        with z.open(filename, 'r') as f:  \n",
    "                            data = f.read()\n",
    "                            # if type_of_file=='asd':\n",
    "                            #     data = pd.json_normalize(json.loads(data))\n",
    "                            #     data =data.rename(columns={'id':'user_id'})\n",
    "                            # else:\n",
    "                            try:\n",
    "                                # data = pd.DataFrame(normalize_json(json.loads(data)))\n",
    "                                data = normalize_json(json.loads(data))\n",
    "                            except: \n",
    "                                print('error on a json')\n",
    "                                continue\n",
    "                            data['news_id'] = re.split(\"\\.+\", zipname)[0]\n",
    "                            data['is_fake_news'] = is_fake_news\n",
    "                            data['tweet_id'] = find_between(filename, '/','.')\n",
    "                            df.append(data) \n",
    "    # df = pd.concat(df)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df\n",
    "\n",
    "def extract_id_from_json(json_col, type_of_file):\n",
    "    id_list = []\n",
    "\n",
    "    if type_of_file=='retweets':\n",
    "        for jsons in tqdm(json_col):\n",
    "            user_id = str(json.loads(json.dumps(jsons))['user']['id'])\n",
    "            id_list.append(user_id)\n",
    "            \n",
    "    elif type_of_file=='replies':\n",
    "        for jsons in tqdm(json_col):\n",
    "            user_id = json.loads(json.dumps(jsons))['user_id']\n",
    "            id_list.append(user_id)\n",
    "\n",
    "    elif type_of_file=='likes':\n",
    "        id_list = json_col\n",
    "   \n",
    "    elif type_of_file=='tweets':\n",
    "        for jsons in tqdm(json_col):\n",
    "            try:\n",
    "                user_id = str(json.loads(json.dumps(jsons))['user']['id'])\n",
    "            except:\n",
    "                user_id = str('')\n",
    "            id_list.append(user_id)\n",
    "\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [00:26<00:00, 16.04it/s]\n"
     ]
    }
   ],
   "source": [
    "## Uncomment to process the original data. Takes a long time.\n",
    "\n",
    "# df_followers = read_files('user_followers.zip')\n",
    "# df_followers = df_followers.explode('followers')\n",
    "# df_followers = df_followers.reset_index()\n",
    "\n",
    "# df_following = read_files('user_following.zip')\n",
    "# df_following = df_following.explode('followees')\n",
    "# df_following = df_following.reset_index()\n",
    "\n",
    "# df_user_profiles = read_files('user_profiles.zip')\n",
    "\n",
    "# news_retweet_fake = read_news_files('politifact_fake.zip', is_fake_news=1, type_of_file='retweets')\n",
    "# news_retweet_fake = news_retweet_fake[news_retweet_fake['retweets'].map(lambda d: len(d)) > 0]\n",
    "# news_retweet_fake['retweets'] = news_retweet_fake['retweets'].map(lambda x: x[0])\n",
    "# news_retweet_fake['user_id'] = extract_id_from_json(news_retweet_fake.retweets.tolist(), type_of_file='retweets')\n",
    "# news_likes_fake = read_news_files('politifact_fake.zip', is_fake_news=1, type_of_file='likes')\n",
    "\n",
    "# news_tweet_fake = read_news_files('politifact_fake.zip', is_fake_news=1, type_of_file='tweets')\n",
    "# news_tweet_fake['user_id'] =  news_tweet_fake['user_id_str']\n",
    "# news_tweet_fake = news_tweet_fake.drop(columns=['id_str','user_id_str'])\n",
    "\n",
    "# news_reply_fake = read_news_files('politifact_fake.zip', is_fake_news=1, type_of_file='replies')\n",
    "\n",
    "# news_retweet_real = read_news_files('politifact_real.zip', is_fake_news=0, type_of_file='retweets')\n",
    "# news_retweet_real = news_retweet_real[news_retweet_real['retweets'].map(lambda d: len(d)) > 0]\n",
    "# news_retweet_real['retweets'] = news_retweet_real['retweets'].map(lambda x: x[0])\n",
    "# news_retweet_real['user_id'] = extract_id_from_json(news_retweet_real.retweets.tolist(), type_of_file='retweets')\n",
    "\n",
    "\n",
    "# news_likes_real = read_news_files('politifact_real.zip', is_fake_news=0, type_of_file='likes')\n",
    "\n",
    "# news_tweet_real = read_news_files('politifact_real.zip', is_fake_news=0, type_of_file='tweets')\n",
    "# news_tweet_real['user_id'] =  news_tweet_real['user_id_str']\n",
    "# news_tweet_real = news_tweet_real.drop(columns=['id_str','user_id_str'])\n",
    "\n",
    "# news_reply_real = read_news_files('politifact_real.zip', is_fake_news=0, type_of_file='replies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment to save the processed unmerged csv\n",
    "\n",
    "# df_followers.to_csv('data/df_followers.csv')\n",
    "# df_following.to_csv('data/df_following.csv')\n",
    "# df_user_profiles.to_csv('data/df_user_profiles.csv')\n",
    "# news_retweet_fake.to_csv('data/news_retweet_fake.csv')\n",
    "# news_likes_fake.to_csv('data/news_likes_fake.csv')\n",
    "# news_tweet_fake.to_csv('data/news_tweet_fake.csv')\n",
    "# news_reply_fake.to_csv('data/news_reply_fake.csv')\n",
    "# news_retweet_real.to_csv('data/news_retweet_real.csv')\n",
    "# news_likes_real.to_csv('data/news_likes_real.csv')\n",
    "# news_tweet_real.to_csv('data/news_tweet_real.csv')\n",
    "# news_reply_real.to_csv('data/news_reply_real.csv')\n",
    "\n",
    "# news_retweet_fake.drop(columns=['retweets'], inplace=True)\n",
    "# news_likes_fake.drop(columns=['likes'], inplace=True)\n",
    "# news_reply_fake.drop(columns=['replies'], inplace=True)\n",
    "# news_retweet_real.drop(columns=['retweets'], inplace=True)\n",
    "# news_likes_real.drop(columns=['likes'], inplace=True)\n",
    "# news_reply_real.drop(columns=['replies'], inplace=True)\n",
    "\n",
    "# df_followers.to_csv('data_summary/df_followers.csv')\n",
    "# df_following.to_csv('data_summary/df_following.csv')\n",
    "# df_user_profiles.to_csv('data_summary/df_user_profiles.csv')\n",
    "# news_retweet_fake.to_csv('data_summary/news_retweet_fake.csv')\n",
    "# news_likes_fake.to_csv('data_summary/news_likes_fake.csv')\n",
    "# news_tweet_fake.to_csv('data_summary/news_tweet_fake.csv')\n",
    "# news_reply_fake.to_csv('data_summary/news_reply_fake.csv')\n",
    "# news_retweet_real.to_csv('data_summary/news_retweet_real.csv')\n",
    "# news_likes_real.to_csv('data_summary/news_likes_real.csv')\n",
    "# news_tweet_real.to_csv('data_summary/news_tweet_real.csv')\n",
    "# news_reply_real.to_csv('data_summary/news_reply_real.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine datasets to make network data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet-Retweet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f2110\\AppData\\Local\\Temp\\ipykernel_26020\\3120968842.py:1: DtypeWarning: Columns (79,84,90,95,111,112,113,114,115,116,117,118,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweet_df = pd.concat([pd.read_csv('data_summary/news_tweet_real.csv', index_col=0, dtype={'user_id':str}), pd.read_csv('data_summary/news_tweet_fake.csv', index_col=0, dtype={'user_id':str})])\n",
      "C:\\Users\\f2110\\AppData\\Local\\Temp\\ipykernel_26020\\3120968842.py:1: DtypeWarning: Columns (99,110,111,112,113,114,115,116,117,118) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweet_df = pd.concat([pd.read_csv('data_summary/news_tweet_real.csv', index_col=0, dtype={'user_id':str}), pd.read_csv('data_summary/news_tweet_fake.csv', index_col=0, dtype={'user_id':str})])\n"
     ]
    }
   ],
   "source": [
    "tweet_df = pd.concat([pd.read_csv('data_summary/news_tweet_real.csv', index_col=0, dtype={'user_id':str}), pd.read_csv('data_summary/news_tweet_fake.csv', index_col=0, dtype={'user_id':str})])\n",
    "retweet_df = pd.concat([pd.read_csv('data_summary/news_retweet_real.csv', index_col=0, dtype={'user_id':str}), pd.read_csv('data_summary/news_retweet_fake.csv', index_col=0, dtype={'user_id':str})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(573637, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id_retweet_df</th>\n",
       "      <th>user_id_tweet_df</th>\n",
       "      <th>news_id</th>\n",
       "      <th>is_fake_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1033706162695356417</td>\n",
       "      <td>787311228</td>\n",
       "      <td>43350851</td>\n",
       "      <td>politifact99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1033706162695356417</td>\n",
       "      <td>787311228</td>\n",
       "      <td>43350851</td>\n",
       "      <td>politifact340</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035580865160638464</td>\n",
       "      <td>3338246572</td>\n",
       "      <td>16297707</td>\n",
       "      <td>politifact99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1035580865160638464</td>\n",
       "      <td>3338246572</td>\n",
       "      <td>16297707</td>\n",
       "      <td>politifact340</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>934206237708865537</td>\n",
       "      <td>754310205546954757</td>\n",
       "      <td>5820642</td>\n",
       "      <td>politifact99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id  user_id_retweet_df user_id_tweet_df        news_id  \\\n",
       "0  1033706162695356417           787311228         43350851   politifact99   \n",
       "3  1033706162695356417           787311228         43350851  politifact340   \n",
       "4  1035580865160638464          3338246572         16297707   politifact99   \n",
       "7  1035580865160638464          3338246572         16297707  politifact340   \n",
       "8   934206237708865537  754310205546954757          5820642   politifact99   \n",
       "\n",
       "   is_fake_news  \n",
       "0           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "7           0.0  \n",
       "8           0.0  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "tweet_retweet_network = retweet_df.merge(tweet_df[['tweet_id','user_id','is_fake_news', 'news_id']], left_on='tweet_id', right_on='tweet_id', how='outer', suffixes=['_retweet_df', '_tweet_df'])\n",
    "tweet_retweet_network = tweet_retweet_network[(tweet_retweet_network['news_id_retweet_df']==tweet_retweet_network['news_id_tweet_df']) | (tweet_retweet_network['news_id_retweet_df'].isna()) | (tweet_retweet_network['news_id_tweet_df'].isna())]\n",
    "tweet_retweet_network = tweet_retweet_network[(tweet_retweet_network['user_id_retweet_df']!=tweet_retweet_network['user_id_tweet_df'])] # Only keep rows where users are different\n",
    "tweet_retweet_network = tweet_retweet_network[(tweet_retweet_network['is_fake_news_retweet_df']==tweet_retweet_network['is_fake_news_tweet_df']) | (tweet_retweet_network['is_fake_news_retweet_df'].isna()) | (tweet_retweet_network['is_fake_news_tweet_df'].isna())] # Only keep rows where labeling is equal or NA\n",
    "\n",
    "\n",
    "tweet_retweet_network['news_id'] = tweet_retweet_network['news_id_tweet_df']\n",
    "tweet_retweet_network['is_fake_news'] = tweet_retweet_network['is_fake_news_tweet_df']\n",
    "\n",
    "tweet_retweet_network.drop(columns=['news_id_retweet_df','is_fake_news_retweet_df','news_id_tweet_df','is_fake_news_tweet_df'], inplace=True)\n",
    "print(tweet_retweet_network.shape)\n",
    "tweet_retweet_network.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 573637 entries, 0 to 586580\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   tweet_id            573637 non-null  int64  \n",
      " 1   user_id_retweet_df  89027 non-null   object \n",
      " 2   user_id_tweet_df    544027 non-null  object \n",
      " 3   news_id             573636 non-null  object \n",
      " 4   is_fake_news        573636 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 26.3+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet_retweet_network.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>871466086293794817</th>\n",
       "      <td>1383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894687595527057415</th>\n",
       "      <td>1362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54039049</th>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161036874</th>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044725409953136640</th>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27368525</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27368623</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736863183</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736870509</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997214389932032</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309034 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tweet_id\n",
       "user_id                      \n",
       "871466086293794817       1383\n",
       "894687595527057415       1362\n",
       "54039049                 1243\n",
       "2161036874                729\n",
       "1044725409953136640       541\n",
       "...                       ...\n",
       "27368525                    1\n",
       "27368623                    1\n",
       "2736863183                  1\n",
       "2736870509                  1\n",
       "999997214389932032          1\n",
       "\n",
       "[309034 rows x 1 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets per user\n",
    "tweet_df[['tweet_id','user_id']].groupby('user_id').count().sort_values(by='tweet_id', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_retweet_network.to_csv('data_summary/tweet_retweet_network.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follower network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f2110\\AppData\\Local\\Temp\\ipykernel_26020\\2501840401.py:1: DtypeWarning: Columns (79,84,90,95,111,112,113,114,115,116,117,118,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweet_df = pd.concat([pd.read_csv('data_summary/news_tweet_real.csv', index_col=0, dtype={'user_id':str}), pd.read_csv('data_summary/news_tweet_fake.csv', index_col=0, dtype={'user_id':str})])\n",
      "C:\\Users\\f2110\\AppData\\Local\\Temp\\ipykernel_26020\\2501840401.py:1: DtypeWarning: Columns (99,110,111,112,113,114,115,116,117,118) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweet_df = pd.concat([pd.read_csv('data_summary/news_tweet_real.csv', index_col=0, dtype={'user_id':str}), pd.read_csv('data_summary/news_tweet_fake.csv', index_col=0, dtype={'user_id':str})])\n"
     ]
    }
   ],
   "source": [
    "tweet_df = pd.concat([pd.read_csv('data_summary/news_tweet_real.csv', index_col=0, dtype={'user_id':str}), pd.read_csv('data_summary/news_tweet_fake.csv', index_col=0, dtype={'user_id':str})])\n",
    "df_followers = pd.read_csv('data_summary/df_followers.csv', index_col=0, dtype={'user_id':str,'followers':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "follower_network = tweet_df[['tweet_id','user_id','is_fake_news', 'news_id']].merge(df_followers, left_on='user_id', right_on='user_id')\n",
    "follower_network = follower_network.rename(columns={'followers':'followers_1'})\n",
    "follower_network2 = follower_network.merge(df_followers, left_on='followers_1', right_on='user_id')[[]]\n",
    "follower_network = follower_network.rename(columns={'followers':'followers_1'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id_x</th>\n",
       "      <th>is_fake_news</th>\n",
       "      <th>news_id</th>\n",
       "      <th>followers_1</th>\n",
       "      <th>user_id_y</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>907064409230643201</td>\n",
       "      <td>153218852</td>\n",
       "      <td>0</td>\n",
       "      <td>politifact99</td>\n",
       "      <td>316449565</td>\n",
       "      <td>316449565</td>\n",
       "      <td>965044995559477248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>907064409230643201</td>\n",
       "      <td>153218852</td>\n",
       "      <td>0</td>\n",
       "      <td>politifact99</td>\n",
       "      <td>316449565</td>\n",
       "      <td>316449565</td>\n",
       "      <td>1053390064791760896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>907064409230643201</td>\n",
       "      <td>153218852</td>\n",
       "      <td>0</td>\n",
       "      <td>politifact99</td>\n",
       "      <td>316449565</td>\n",
       "      <td>316449565</td>\n",
       "      <td>261045341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>907064409230643201</td>\n",
       "      <td>153218852</td>\n",
       "      <td>0</td>\n",
       "      <td>politifact99</td>\n",
       "      <td>316449565</td>\n",
       "      <td>316449565</td>\n",
       "      <td>977013050518704128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>907064409230643201</td>\n",
       "      <td>153218852</td>\n",
       "      <td>0</td>\n",
       "      <td>politifact99</td>\n",
       "      <td>316449565</td>\n",
       "      <td>316449565</td>\n",
       "      <td>3343757261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63633459</th>\n",
       "      <td>1034741192817295360</td>\n",
       "      <td>861663665719840773</td>\n",
       "      <td>1</td>\n",
       "      <td>politifact15514</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>3306283622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63633460</th>\n",
       "      <td>1034741192817295360</td>\n",
       "      <td>861663665719840773</td>\n",
       "      <td>1</td>\n",
       "      <td>politifact15514</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>4102376488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63633461</th>\n",
       "      <td>1034741192817295360</td>\n",
       "      <td>861663665719840773</td>\n",
       "      <td>1</td>\n",
       "      <td>politifact15514</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>4165642155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63633462</th>\n",
       "      <td>1034741192817295360</td>\n",
       "      <td>861663665719840773</td>\n",
       "      <td>1</td>\n",
       "      <td>politifact15514</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>384708626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63633463</th>\n",
       "      <td>1034741192817295360</td>\n",
       "      <td>861663665719840773</td>\n",
       "      <td>1</td>\n",
       "      <td>politifact15514</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>804235634890010625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63633464 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tweet_id           user_id_x  is_fake_news  \\\n",
       "0          907064409230643201           153218852             0   \n",
       "1          907064409230643201           153218852             0   \n",
       "2          907064409230643201           153218852             0   \n",
       "3          907064409230643201           153218852             0   \n",
       "4          907064409230643201           153218852             0   \n",
       "...                       ...                 ...           ...   \n",
       "63633459  1034741192817295360  861663665719840773             1   \n",
       "63633460  1034741192817295360  861663665719840773             1   \n",
       "63633461  1034741192817295360  861663665719840773             1   \n",
       "63633462  1034741192817295360  861663665719840773             1   \n",
       "63633463  1034741192817295360  861663665719840773             1   \n",
       "\n",
       "                  news_id followers_1   user_id_y            followers  \n",
       "0            politifact99   316449565   316449565   965044995559477248  \n",
       "1            politifact99   316449565   316449565  1053390064791760896  \n",
       "2            politifact99   316449565   316449565            261045341  \n",
       "3            politifact99   316449565   316449565   977013050518704128  \n",
       "4            politifact99   316449565   316449565           3343757261  \n",
       "...                   ...         ...         ...                  ...  \n",
       "63633459  politifact15514  3416678236  3416678236           3306283622  \n",
       "63633460  politifact15514  3416678236  3416678236           4102376488  \n",
       "63633461  politifact15514  3416678236  3416678236           4165642155  \n",
       "63633462  politifact15514  3416678236  3416678236            384708626  \n",
       "63633463  politifact15514  3416678236  3416678236   804235634890010625  \n",
       "\n",
       "[63633464 rows x 7 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follower_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweet_retweet_follower_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_followers = pd.read_csv('data_summary/df_followers.csv', index_col=0, dtype={'user_id':str,'followers':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_fake_news</th>\n",
       "      <th>follow_or_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>787311228</td>\n",
       "      <td>43350851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3338246572</td>\n",
       "      <td>16297707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>754310205546954757</td>\n",
       "      <td>5820642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2157919340</td>\n",
       "      <td>1716121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4867759271</td>\n",
       "      <td>31056977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>retweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18258071</th>\n",
       "      <td>3306283622</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>follower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18258072</th>\n",
       "      <td>4102376488</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>follower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18258073</th>\n",
       "      <td>4165642155</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>follower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18258074</th>\n",
       "      <td>384708626</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>follower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18258075</th>\n",
       "      <td>804235634890010625</td>\n",
       "      <td>3416678236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>follower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4032407 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   followers     user_id  is_fake_news follow_or_retweet\n",
       "0                  787311228    43350851           0.0           retweet\n",
       "4                 3338246572    16297707           0.0           retweet\n",
       "8         754310205546954757     5820642           0.0           retweet\n",
       "9                 2157919340     1716121           0.0           retweet\n",
       "13                4867759271    31056977           0.0           retweet\n",
       "...                      ...         ...           ...               ...\n",
       "18258071          3306283622  3416678236           NaN          follower\n",
       "18258072          4102376488  3416678236           NaN          follower\n",
       "18258073          4165642155  3416678236           NaN          follower\n",
       "18258074           384708626  3416678236           NaN          follower\n",
       "18258075  804235634890010625  3416678236           NaN          follower\n",
       "\n",
       "[4032407 rows x 4 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retweets\n",
    "tweet_retweet_follower_network = tweet_retweet_network[['user_id_tweet_df']]\n",
    "\n",
    "\n",
    "# Followers of tweets\n",
    "tweet_retweet_follower_network = tweet_retweet_follower_network.merge(df_followers, left_on = 'user_id_tweet_df', right_on = 'user_id')\n",
    "\n",
    "tweet_retweet_follower_network.drop(columns=['user_id_tweet_df'], inplace=True)\n",
    "tweet_retweet_follower_network.drop_duplicates(inplace=True)\n",
    "\n",
    "# Followers of followers\n",
    "followers_of_followers = tweet_retweet_follower_network[['followers']]\n",
    "followers_of_followers = followers_of_followers.rename(columns={'followers':'user_id'})\n",
    "followers_of_followers = followers_of_followers.merge(df_followers, left_on = 'user_id', right_on = 'user_id', suffixes=['_1','_2'])\n",
    "# followers_of_followers.drop(columns=['user_id'], inplace=True)\n",
    "followers_of_followers.drop_duplicates(inplace=True)\n",
    "\n",
    "# Join FoF with FoT\n",
    "tweet_retweet_follower_network = pd.concat([tweet_retweet_follower_network,followers_of_followers])\n",
    "tweet_retweet_follower_network = tweet_retweet_follower_network.drop_duplicates()\n",
    "tweet_retweet_follower_network['follow_or_retweet'] = tweet_retweet_follower_network['user_id']+tweet_retweet_follower_network['followers']\n",
    "list = tweet_retweet_network['user_id_tweet_df']+tweet_retweet_network['user_id_tweet_df']\n",
    "follow_and_retweet = [1 if x in list else 0 for x in tweet_retweet_follower_network['follow_or_retweet'] ]\n",
    "tweet_retweet_follower_network['follow_or_retweet'] = follow_and_retweet\n",
    "# Join with retweets\n",
    "tweet_retweet_follower_network = pd.concat([tweet_retweet_network[['user_id_retweet_df','user_id_tweet_df','is_fake_news']].rename(columns={'user_id_retweet_df':'followers','user_id_tweet_df':'user_id'}), tweet_retweet_follower_network])\n",
    "tweet_retweet_follower_network = tweet_retweet_follower_network[tweet_retweet_follower_network['follow_or_retweet']!=1]\n",
    "tweet_retweet_follower_network.drop(columns=['follow_or_retweet'], inplace=True)\n",
    "tweet_retweet_follower_network = tweet_retweet_follower_network.drop_duplicates(subset=['followers','user_id'])\n",
    "\n",
    "import math\n",
    "tweet_retweet_follower_network['follow_or_retweet'] = tweet_retweet_follower_network['is_fake_news'].map(lambda x: 'follower' if math.isnan(x) else 'retweet')\n",
    "tweet_retweet_follower_network\n",
    "\n",
    "tweet_retweet_follower_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_retweet_follower_network.to_csv('data_summary/tweet_retweet_follower_network.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
